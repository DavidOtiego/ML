{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 1728\n",
      "Number of features: 6\n",
      "Feature column(s):-\n",
      "['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']\n",
      "Target column: expected_output\n",
      "\n",
      "Feature values:-\n",
      "  buying  maint doors persons lug_boot safety\n",
      "0  vhigh  vhigh     2       2    small    low\n",
      "1  vhigh  vhigh     2       2    small    med\n",
      "2  vhigh  vhigh     2       2    small   high\n",
      "3  vhigh  vhigh     2       2      med    low\n",
      "4  vhigh  vhigh     2       2      med    med\n",
      "Processed feature columns (21):-\n",
      "['buying_high', 'buying_low', 'buying_med', 'buying_vhigh', 'maint_high', 'maint_low', 'maint_med', 'maint_vhigh', 'doors_2', 'doors_3', 'doors_4', 'doors_5more', 'persons_2', 'persons_4', 'persons_more', 'lug_boot_big', 'lug_boot_med', 'lug_boot_small', 'safety_high', 'safety_low', 'safety_med']\n",
      "Training set: 1382 samples\n",
      "Test set: 346 samples\n",
      "Training LinearSVC...\n",
      "Done!\n",
      "Training time (secs): 0.185\n",
      "Final F1 score: 0.8901734104046243\n",
      "Training GradientBoostingClassifier...\n",
      "Done!\n",
      "Training time (secs): 1.172\n",
      "Final F1 score: 0.9161849710982659\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.000\n",
      "Final F1 score: 0.9682080924855492\n",
      "Prediction\n",
      "['unacc' 'unacc' 'unacc' 'unacc' 'acc' 'unacc' 'unacc' 'unacc' 'unacc'\n",
      " 'acc' 'unacc' 'unacc' 'unacc' 'unacc' 'acc' 'acc' 'acc' 'acc' 'unacc'\n",
      " 'unacc' 'unacc' 'unacc' 'vgood' 'unacc' 'unacc' 'acc' 'unacc' 'unacc'\n",
      " 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'acc' 'acc'\n",
      " 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'acc'\n",
      " 'acc' 'acc' 'acc' 'acc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc'\n",
      " 'unacc' 'unacc' 'unacc' 'acc' 'acc' 'unacc' 'unacc' 'unacc' 'unacc'\n",
      " 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'acc' 'unacc' 'unacc'\n",
      " 'acc' 'unacc' 'unacc' 'acc' 'unacc' 'acc' 'unacc' 'unacc' 'unacc' 'unacc'\n",
      " 'acc' 'acc' 'acc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc'\n",
      " 'unacc' 'unacc' 'acc' 'unacc' 'acc' 'acc' 'unacc' 'unacc' 'unacc' 'unacc'\n",
      " 'unacc' 'good' 'unacc' 'unacc' 'acc' 'acc' 'unacc' 'unacc' 'unacc' 'unacc'\n",
      " 'unacc' 'unacc' 'unacc' 'unacc' 'good' 'unacc' 'unacc' 'unacc' 'unacc'\n",
      " 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'acc' 'unacc'\n",
      " 'unacc' 'unacc' 'vgood' 'unacc' 'unacc' 'acc' 'unacc' 'unacc' 'unacc'\n",
      " 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc'\n",
      " 'unacc' 'vgood' 'unacc' 'acc' 'unacc' 'acc' 'unacc' 'vgood' 'unacc' 'acc'\n",
      " 'unacc' 'unacc' 'vgood' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc'\n",
      " 'unacc' 'unacc' 'unacc' 'acc' 'unacc' 'acc' 'unacc' 'acc' 'acc' 'acc'\n",
      " 'unacc' 'unacc' 'vgood' 'unacc' 'good' 'unacc' 'acc' 'unacc' 'unacc' 'acc'\n",
      " 'unacc' 'unacc' 'unacc' 'unacc' 'acc' 'unacc' 'acc' 'unacc' 'unacc'\n",
      " 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'acc'\n",
      " 'unacc' 'acc' 'unacc' 'acc' 'acc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc'\n",
      " 'acc' 'unacc' 'unacc' 'unacc' 'acc' 'unacc' 'unacc' 'unacc' 'unacc'\n",
      " 'unacc' 'unacc' 'unacc' 'acc' 'unacc' 'unacc' 'acc' 'acc' 'unacc' 'vgood'\n",
      " 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'acc' 'unacc' 'unacc'\n",
      " 'unacc' 'acc' 'unacc' 'unacc' 'unacc' 'acc' 'unacc' 'unacc' 'unacc'\n",
      " 'unacc' 'acc' 'acc' 'unacc' 'acc' 'unacc' 'good' 'unacc' 'unacc' 'unacc'\n",
      " 'unacc' 'acc' 'unacc' 'unacc' 'acc' 'acc' 'unacc' 'acc' 'unacc' 'unacc'\n",
      " 'acc' 'acc' 'vgood' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'acc' 'acc'\n",
      " 'vgood' 'unacc' 'unacc' 'acc' 'acc' 'unacc' 'unacc' 'unacc' 'acc' 'acc'\n",
      " 'unacc' 'unacc' 'acc' 'unacc' 'acc' 'unacc' 'unacc' 'unacc' 'good' 'acc'\n",
      " 'unacc' 'unacc' 'acc' 'unacc' 'acc' 'acc' 'acc' 'unacc' 'unacc' 'unacc'\n",
      " 'unacc' 'unacc' 'unacc' 'good' 'unacc' 'acc' 'acc' 'unacc' 'unacc' 'unacc'\n",
      " 'acc' 'unacc' 'acc' 'good' 'acc' 'unacc' 'acc' 'unacc' 'unacc' 'acc'\n",
      " 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'unacc' 'good' 'unacc' 'unacc'\n",
      " 'unacc' 'unacc' 'unacc']\n",
      "Expected\n",
      "1099    unacc\n",
      "559     unacc\n",
      "981     unacc\n",
      "685     unacc\n",
      "911       acc\n",
      "1638    unacc\n",
      "100     unacc\n",
      "901     unacc\n",
      "158     unacc\n",
      "836       acc\n",
      "253     unacc\n",
      "325     unacc\n",
      "790     unacc\n",
      "1018    unacc\n",
      "1711      acc\n",
      "428       acc\n",
      "1064      acc\n",
      "1426      acc\n",
      "440     unacc\n",
      "229     unacc\n",
      "1527    unacc\n",
      "32      unacc\n",
      "1151    vgood\n",
      "1281    unacc\n",
      "618     unacc\n",
      "1397      acc\n",
      "1671    unacc\n",
      "726     unacc\n",
      "1223    unacc\n",
      "245     unacc\n",
      "        ...  \n",
      "849     unacc\n",
      "1714     good\n",
      "545     unacc\n",
      "1184    vgood\n",
      "560     unacc\n",
      "503     unacc\n",
      "1568    unacc\n",
      "1083    unacc\n",
      "889       acc\n",
      "1189    unacc\n",
      "1079      acc\n",
      "1228      acc\n",
      "773       acc\n",
      "1332    unacc\n",
      "862       acc\n",
      "256     unacc\n",
      "489     unacc\n",
      "1349      acc\n",
      "802     unacc\n",
      "1396    unacc\n",
      "182     unacc\n",
      "529     unacc\n",
      "1193    unacc\n",
      "1195    unacc\n",
      "1561     good\n",
      "913       acc\n",
      "874     unacc\n",
      "3       unacc\n",
      "1531    unacc\n",
      "1116    unacc\n",
      "Name: expected_output, Length: 346, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\"\n",
    "names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety','expected_output']\n",
    "\n",
    "dataset = pd.read_csv(url, names=names)\n",
    "\n",
    "\n",
    "#data = numpy.array(dataset)  #convert array to numpy type array\n",
    "#x_train, x_test = train_test_split(data,test_size=0.20)\n",
    "\n",
    "#Info on dataset\n",
    "n_rows = dataset.shape[0]\n",
    "n_features = dataset.shape[1] - 1\n",
    "print( \"Total number of rows: {}\".format(n_rows))\n",
    "print( \"Number of features: {}\".format(n_features))\n",
    "\n",
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(dataset.columns[:-1])  # all columns but last is target/label\n",
    "target_col = dataset.columns[-1]  # last column is the target/label\n",
    "print( \"Feature column(s):-\\n{}\".format(feature_cols))\n",
    "print( \"Target column: {}\".format(target_col))\n",
    "\n",
    "X_all = dataset[feature_cols]  # feature values for all cars\n",
    "y_all = dataset[target_col]  # corresponding targets/labels\n",
    "print (\"\\nFeature values:-\")\n",
    "print( X_all.head())  # print the first 5 rows\n",
    "\n",
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    #pd refers to pandas library\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        #if col_data.dtype == object:\n",
    "            #col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'safety' => 'safety_LOW', 'safety_MED', 'safety_HIGH'\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "\n",
    "    return outX\n",
    "#prepare the dataset before processing it, non-numeric values need to be converted\n",
    "X_all = preprocess_features(X_all)\n",
    "print( \"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns)))\n",
    "\n",
    "# TODO: Then, select features (X) and corresponding labels (y) for the training and test sets\n",
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=0.80)\n",
    "\n",
    "print (\"Training set: {} samples\".format(X_train.shape[0]))\n",
    "print (\"Test set: {} samples\".format(X_test.shape[0]))\n",
    "# Note: Validation set can be extracted from training data if needed\n",
    "\n",
    "#training method\n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print( \"Training {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print (\"Done!\\nTraining time (secs): {:.3f}\".format(end - start))\n",
    "    f1_final = clf.score(X_test,y_test,sample_weight=None)\n",
    "    print (\"Final F1 score: {}\".format(f1_final))\n",
    "    \n",
    "\n",
    "#training with LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
    "     verbose=0)\n",
    "train_classifier(clf,X_train,y_train)\n",
    "#training with GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "train_classifier(clf,X_train,y_train)\n",
    "\n",
    "# training with DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "train_classifier(clf,X_train,y_train)\n",
    "\n",
    "#predict with the best model\n",
    "print(\"Prediction made by the best model\")\n",
    "print(clf.predict(X_test))\n",
    "print(\"Expected output\")\n",
    "print(y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
