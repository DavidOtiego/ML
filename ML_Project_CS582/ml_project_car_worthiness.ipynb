{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 1728\n",
      "Number of features: 6\n",
      "Feature column(s):-\n",
      "['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']\n",
      "Target column: expected_output\n",
      "\n",
      "Feature values:-\n",
      "  buying  maint doors persons lug_boot safety\n",
      "0  vhigh  vhigh     2       2    small    low\n",
      "1  vhigh  vhigh     2       2    small    med\n",
      "2  vhigh  vhigh     2       2    small   high\n",
      "3  vhigh  vhigh     2       2      med    low\n",
      "4  vhigh  vhigh     2       2      med    med\n",
      "Processed feature columns (21):-\n",
      "['buying_high', 'buying_low', 'buying_med', 'buying_vhigh', 'maint_high', 'maint_low', 'maint_med', 'maint_vhigh', 'doors_2', 'doors_3', 'doors_4', 'doors_5more', 'persons_2', 'persons_4', 'persons_more', 'lug_boot_big', 'lug_boot_med', 'lug_boot_small', 'safety_high', 'safety_low', 'safety_med']\n",
      "Training set: 1382 samples\n",
      "Test set: 346 samples\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.047\n",
      "Final F1 score: 0.9826589595375722\n",
      "Training LinearSVC...\n",
      "Done!\n",
      "Training time (secs): 1.272\n",
      "Final F1 score: 0.9046242774566474\n",
      "Training GradientBoostingClassifier...\n",
      "Done!\n",
      "Training time (secs): 1.149\n",
      "Final F1 score: 0.9277456647398844\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\"\n",
    "names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety','expected_output']\n",
    "\n",
    "dataset = pd.read_csv(url, names=names)\n",
    "\n",
    "\n",
    "#data = numpy.array(dataset)  #convert array to numpy type array\n",
    "#x_train, x_test = train_test_split(data,test_size=0.20)\n",
    "\n",
    "#Info on dataset\n",
    "n_rows = dataset.shape[0]\n",
    "n_features = dataset.shape[1] - 1\n",
    "print( \"Total number of rows: {}\".format(n_rows))\n",
    "print( \"Number of features: {}\".format(n_features))\n",
    "\n",
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(dataset.columns[:-1])  # all columns but last is target/label\n",
    "target_col = dataset.columns[-1]  # last column is the target/label\n",
    "print( \"Feature column(s):-\\n{}\".format(feature_cols))\n",
    "print( \"Target column: {}\".format(target_col))\n",
    "\n",
    "X_all = dataset[feature_cols]  # feature values for all cars\n",
    "y_all = dataset[target_col]  # corresponding targets/labels\n",
    "print (\"\\nFeature values:-\")\n",
    "print( X_all.head())  # print the first 5 rows\n",
    "\n",
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    #pd refers to pandas library\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        #if col_data.dtype == object:\n",
    "            #col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'safety' => 'safety_LOW', 'safety_MED', 'safety_HIGH'\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "\n",
    "    return outX\n",
    "#prepare the dataset before processing it, non-numeric values need to be converted\n",
    "X_all = preprocess_features(X_all)\n",
    "print( \"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns)))\n",
    "\n",
    "# TODO: Then, select features (X) and corresponding labels (y) for the training and test sets\n",
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=0.80)\n",
    "\n",
    "print (\"Training set: {} samples\".format(X_train.shape[0]))\n",
    "print (\"Test set: {} samples\".format(X_test.shape[0]))\n",
    "# Note: Validation set can be extracted from training data if needed\n",
    "\n",
    "#training method\n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print( \"Training {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print (\"Done!\\nTraining time (secs): {:.3f}\".format(end - start))\n",
    "    f1_final = clf.score(X_test,y_test,sample_weight=None)\n",
    "    print (\"Final F1 score: {}\".format(f1_final))\n",
    "    \n",
    "    \n",
    "# training with DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "train_classifier(clf,X_train,y_train)\n",
    "\n",
    "#training with LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
    "     verbose=0)\n",
    "train_classifier(clf,X_train,y_train)\n",
    "#training with GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "train_classifier(clf,X_train,y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
